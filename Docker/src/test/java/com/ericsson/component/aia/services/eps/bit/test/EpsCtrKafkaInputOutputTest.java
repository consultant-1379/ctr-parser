/*------------------------------------------------------------------------------
 *******************************************************************************
 * COPYRIGHT Ericsson 2018
 *
 * The copyright to the computer program(s) herein is the property of
 * Ericsson Inc. The programs may be used and/or copied only with written
 * permission from Ericsson Inc. or in accordance with the terms and
 * conditions stipulated in the agreement/contract under which the
 * program(s) have been supplied.
 *******************************************************************************
 *----------------------------------------------------------------------------*/
package com.ericsson.component.aia.services.eps.bit.test;

import static com.github.tomakehurst.wiremock.client.WireMock.aResponse;
import static com.github.tomakehurst.wiremock.client.WireMock.get;
import static com.github.tomakehurst.wiremock.client.WireMock.stubFor;
import static com.github.tomakehurst.wiremock.client.WireMock.urlPathMatching;

import java.io.File;
import java.io.FileInputStream;
import java.io.InputStream;
import java.util.concurrent.CountDownLatch;

import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.TemporaryFolder;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.ericsson.component.aia.services.eps.core.embeddedservices.EmbeddedEPS;
import com.ericsson.component.aia.services.eps.core.embeddedservices.EmbeddedKafka;
import com.ericsson.component.aia.services.eps.core.embeddedservices.KafkaGenericRecordConsumer;
import com.ericsson.component.aia.services.eps.core.util.Constants;
import com.ericsson.component.aia.services.eps.core.util.TestUtility;
import com.github.tomakehurst.wiremock.junit.WireMockRule;

/**
 * The {@linkplain EpsCtrKafkaInputOutputTest} do the basic bit integration test for EPS.
 */
public class EpsCtrKafkaInputOutputTest extends BaseTest {
    private static final Logger LOG = LoggerFactory.getLogger(EpsCtrKafkaInputOutputTest.class);
    private static final String APPLICATION_JSON = "application/json";

    /**
     * temporary solution for the JMX metrics values.
     *
     * all the metrics are read-only attributes and can not be reset, these fields keep the current metrics value during test start. And the Assert
     * will check the final values, which consist of current values and updates.
     */
    private static long erroneousFiles = 0;
    private static long fileCounts = 0;
    private static long eventProcessed = 0;
    private static long ignoredEvents = 0;

    /**
     * Use WireMock to simulate the REST interface.
     */
    @Rule
    public WireMockRule wireMockRule = new WireMockRule(WIREMOCK_PORT);

    @Rule
    public TemporaryFolder folder = new TemporaryFolder();

    /**
     * Embedded EPS provider.
     */
    private EmbeddedEPS embeddedEps = new EmbeddedEPS();;
    /**
     * EmbeddedKafka provider.
     */
    private EmbeddedKafka embeddedKafka;
    /**
     * Embedded Consumer.
     */
    private KafkaGenericRecordConsumer kafkaConsumer;

    /**
     * Temporary directory for test.
     */
    private File createTempDir;
    /**
     * Temporary directory for output generated by consumer.
     */
    private File consumerOutputDir;

    /**
     * Latch to wait till all the require precondition fulfill.
     */
    CountDownLatch latch = new CountDownLatch(2);

    /**
     * Initialize precondition before every test.
     *
     * @throws Exception
     *             if unable to setup precondition require for test.
     */
    @Before
    public void setup() throws Exception {
        createTempDir = folder.newFolder("kafka_test_dir");

        consumerOutputDir = new File(createTempDir.getAbsolutePath(), "testresult");
        consumerOutputDir.mkdir();

        System.setProperty("schemaRegistry.address", Constants.AVRO_SCHEMA_DIR);
        System.setProperty("com.ericsson.component.aia.services.eps.module.deployment.folder.path", createTempDir.getAbsolutePath());
        embeddedKafka = new EmbeddedKafka(createTempDir);
        configureWireMock(EMPTY_FILTERLIST);
        embeddedEps.createEpsInstanceInNewThread();

        /**
         * read the current jmx metrics value during start.
         */
        erroneousFiles = TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_ERRONEOUS_FILES, Constants.JMX_METER_ATTRIBUTE_NAME);
        fileCounts = TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_FILE_COUNTS, Constants.JMX_METER_ATTRIBUTE_NAME);
        eventProcessed = TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_EVENTS_PROCESSED, Constants.JMX_METER_ATTRIBUTE_NAME);
        ignoredEvents = TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_IGNORED_EVENTS, Constants.JMX_METER_ATTRIBUTE_NAME);
    }

    private void configureWireMock(final String response) {
        stubFor(get(urlPathMatching(EVENTLIST_URL))
                .willReturn(aResponse().withStatus(200).withHeader("Content-Type", APPLICATION_JSON).withBody(response)));
    }

    /**
     * clean all the resources allocated for the test.
     */
    @After
    public void tearDown() {
        kafkaConsumer.stop();
        //
        //embeddedKafka.deleteTestTopic(inputTopic);
        //embeddedKafka.deleteTestTopic(outputTopic);
        embeddedEps.shutdownEpsInstance();
        embeddedKafka.shutdownAndCleanUpServices();
        try {
            // do delay in order to close all the services.
            Thread.sleep(1000);
        } catch (final InterruptedException e) {
            LOG.error("Error will wating for task to finished ", e);
        }
    }

    @Test
    public void test_basicEPSFlowWithKafka_verifyDataIntegrity() throws Exception {

        Assert.assertEquals(0, embeddedEps.getDeployedModulesCount());
        super.kafkaBrokerList = embeddedKafka.getKafkaBrokerUrl();
        final File createFlowAndConfigFiles = createFlowAndConfigFiles(createTempDir);
        final InputStream file = new FileInputStream(createFlowAndConfigFiles);
        embeddedKafka.createTopic(inputTopic, 1, 1);
        embeddedKafka.createTopic(outputTopic, 1, 1);

        deployEpsFlow(file);

        final File srcFile = new File(Constants.TEST_FILE_PATH);
        final String absolutePath = srcFile.getAbsolutePath();
        LOG.info("Publishing message on kafka topic ........ {}  and path {}", inputTopic, absolutePath);
        publishFileLocationToKafkaTopic(inputTopic, absolutePath);
        LOG.info("Published message on kafka topic ........ {}  ", inputTopic);

        kafkaConsumer = new KafkaGenericRecordConsumer(consumerOutputDir, outputTopic, super.kafkaBrokerList,
                embeddedKafka.getZookeeperConnectionUrl());
        kafkaConsumer.start();

        initializeWatingCondition(128);

        // wait till latch count ==0
        latch.await();

        // close the consumer
        kafkaConsumer.stop();

        //validate JMX
        Assert.assertEquals(0 + erroneousFiles,
                TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_ERRONEOUS_FILES, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertEquals(1 + fileCounts, TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_FILE_COUNTS, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertEquals(128 + eventProcessed,
                TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_EVENTS_PROCESSED, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertEquals(0 + ignoredEvents,
                TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_IGNORED_EVENTS, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertTrue(super.compareResult(srcFile.getParentFile(), Constants.TEST_RESUTL_FILE_FILTER, consumerOutputDir,
                Constants.TEST_RESUTL_FILE_FILTER));

        // EPS does not support multiple instance hence combining negative scenario to check the invalid files
        publishFileLocationToKafkaTopic(inputTopic, new File(Constants.CORRUPT_TEST_FILE_PATH).getAbsolutePath());
        Thread.sleep(10000);

        //validate JMX
        Assert.assertEquals(1 + erroneousFiles,
                TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_ERRONEOUS_FILES, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertEquals(2 + fileCounts, TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_FILE_COUNTS, Constants.JMX_METER_ATTRIBUTE_NAME));

        Assert.assertEquals(1, embeddedEps.undeployAllModules());

    }

    @Test
    public void test_basicEPSFlowWithKafkaWithFilter_verifyDataIntegrity() throws Exception {

        Assert.assertEquals(0, embeddedEps.getDeployedModulesCount());
        super.kafkaBrokerList = embeddedKafka.getKafkaBrokerUrl();
        configureWireMock(FILTERLIST);
        final File createFlowAndConfigFiles = createFlowAndConfigFiles(createTempDir);
        final InputStream file = new FileInputStream(createFlowAndConfigFiles);
        embeddedKafka.createTopic(inputTopic, 1, 1);
        embeddedKafka.createTopic(outputTopic, 1, 1);

        deployEpsFlow(file);

        final File srcFile = new File(Constants.TEST_FILE_PATH);
        final String absolutePath = srcFile.getAbsolutePath();
        LOG.info("Publishing message on kafka topic ........ {}  and path {}", inputTopic, absolutePath);
        publishFileLocationToKafkaTopic(inputTopic, absolutePath);
        LOG.info("Published message on kafka topic ........ {}  ", inputTopic);

        kafkaConsumer = new KafkaGenericRecordConsumer(consumerOutputDir, outputTopic, super.kafkaBrokerList,
                embeddedKafka.getZookeeperConnectionUrl());
        kafkaConsumer.start();

        initializeWatingCondition(36);

        // wait till latch count ==0
        latch.await();

        // close the consumer
        kafkaConsumer.stop();

        //validate JMX
        Assert.assertEquals(0 + erroneousFiles,
                TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_ERRONEOUS_FILES, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertEquals(1 + fileCounts, TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_FILE_COUNTS, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertEquals(36 + eventProcessed,
                TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_EVENTS_PROCESSED, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertEquals(92 + ignoredEvents,
                TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_IGNORED_EVENTS, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertTrue(super.compareResult(srcFile.getParentFile(), Constants.TEST_RESUTL_FILE_FILTER, consumerOutputDir,
                Constants.TEST_RESUTL_FILE_FILTER, "UE_MEAS_INTRAFREQ1", "INTERNAL_PER_RADIO_UE_MEASUREMENT_TA"));

        // EPS does not support multiple instance hence combining negative scenario to check the invalid files
        publishFileLocationToKafkaTopic(inputTopic, new File(Constants.CORRUPT_TEST_FILE_PATH).getAbsolutePath());
        Thread.sleep(10000);

        //validate JMX
        Assert.assertEquals(1 + erroneousFiles,
                TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_ERRONEOUS_FILES, Constants.JMX_METER_ATTRIBUTE_NAME));
        Assert.assertEquals(2 + fileCounts, TestUtility.getJMXvalues(Constants.JMX_PM_FILE_PARSER_FILE_COUNTS, Constants.JMX_METER_ATTRIBUTE_NAME));

        Assert.assertEquals(1, embeddedEps.undeployAllModules());

    }

    /**
     * Deploy file and wait till module is deploy successfully and decrement latch by 1.
     *
     * @param file
     *            flow file.
     */
    private void deployEpsFlow(final InputStream file) {
        Assert.assertNotNull(file);
        LOG.info("Deploying eps modules....");
        embeddedEps.deployModuleFromFile(file);
        LOG.info("Deployed eps modules....");

        final Thread waitForEpsToDeployModules = new Thread(() -> {
            int attempt = 0;
            while (!(embeddedEps.getDeployedModulesCount() == 1)) {
                try {
                    Thread.sleep(1000);
                } catch (final Exception e) {
                    LOG.error("Error occured wile wating for module to deploy  latch count " + latch.getCount(), e);
                }
                LOG.info("Looking for deployed module counts {} and attempt {}  and latch count {} ", embeddedEps.getDeployedModulesCount(), attempt,
                        latch.getCount());
                ++attempt;
            }
            if (embeddedEps.getDeployedModulesCount() == 1) {
                latch.countDown();
                LOG.info("Deploy EPS module Latch count {} ", latch.getCount());
            }

        }, "watcher-EpsModuleDeployeWatcher");
        waitForEpsToDeployModules.start();
    }

    /**
     * Wait till desired condition satisfied for current test.
     *
     * @param messageCount
     *            message count to be checked.
     */
    private void initializeWatingCondition(final int messageCount) {
        final Thread waitForOutput = new Thread(() -> {
            while (kafkaConsumer.getConsumeCount() < messageCount) {
                LOG.debug("Consumer count is {}", kafkaConsumer.getConsumeCount());
                try {
                    Thread.sleep(1000);
                } catch (final InterruptedException e) {
                    LOG.error("Error occured wile waiting for output directory  latch count " + latch.getCount(), e);
                }
            }
            //try to sleep one more second to ensure output content populate properly
            try {
                LOG.info("Taking 2 seconds delay to ensure that all open thread finished its taks.... latch count {} consumer records {} ",
                        latch.getCount(), kafkaConsumer.getConsumeCount());
                Thread.sleep(2000);
            } catch (final InterruptedException e) {
                LOG.error("Error occured wile waiting for output directory  latch count " + latch.getCount(), e);
            }
            latch.countDown();

        }, "watcher-OutputContentWatcher");
        waitForOutput.start();
    }

}
